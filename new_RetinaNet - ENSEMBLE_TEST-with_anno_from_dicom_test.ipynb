{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이 프로그램은 Ensemble 테스트 전용으로 annotation 처리는 제외한다.\n",
    "#신규방식인 각 모델 결과를 모아서 최적의 영역을 선택 추출\n",
    "#이전 방식(한 모델의 결과를 걸러 다음 모델로 넘겨 테스트)은 new_RetinaNet - TEST.ipynb 참조\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "from itertools import chain\n",
    "from operator import eq\n",
    "import keras\n",
    "import keras.preprocessing.image\n",
    "from keras_retinanet.models.resnet import custom_objects\n",
    "from keras_retinanet.preprocessing.csv_generator import CSVGenerator\n",
    "from keras_retinanet.preprocessing.dicom2jpg_generator import DICOM2JPG_Generator\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import keras_retinanet.utils.new_util as my\n",
    "\n",
    "OS_ENV = 'LINUX' # 'LINUX' or 'WIN'\n",
    "MODEL_ENV = 'ensemble' # 'ensemble' or 'separate'\n",
    "DATE = '20181122_from_dicom_with_merge'\n",
    "DATA_TO_TEST = 'abn_all' # 'abn1' or 'abn2' or 'abn_all' or 'normal' or 'normal_1'\n",
    "#normal_1': #2018. 1월말 데이터중 Normal 1318 file\n",
    "DATA_SOURCE_TYPE = '_MEM_' #메모리 = _MEM_, 파일 = _FILE_\n",
    "\n",
    "#SCORE_VALUE_LIST = [0.5,0.4]\n",
    "SCORE_VALUE_LIST = [0.4]\n",
    "\n",
    "ordinal=lambda x:[\"1st\",\"2nd\",\"3rd\",\"4th\",\"5th\",\"6th\"][x-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OS_ENV == 'LINUX':\n",
    "    app_base_path = '/home/huray/workspace/han_work/han_test'\n",
    "    data_base_path = \"/home/huray/data/NCC\"\n",
    "else:\n",
    "    app_base_path = 'D:/Work/NCC/han_test'\n",
    "    data_base_path = \"D:/Work/NCC/data/NCC\"\n",
    "\n",
    "#----test file list for detect-----#\n",
    "test_file_list = [] #전체 테스트 파일 목록, full path\n",
    "test_file_name_list = [] #전체 데스트 파일명 목록, path를 제외, 폴더명+파일명 조함으로 unique한 name 구성\n",
    "num_of_test_files = 0 #전체 테스대상 파일 개수\n",
    "\n",
    "#--------------- dicom 관련 ----------------------------#\n",
    "#dicom 및 jpg file path    \n",
    "dicom_base_path = os.path.join(data_base_path, \"dicom_test\")\n",
    "#jpg_base_path = dicom_base_path.replace('dicom', 'img_retinanet')\n",
    "jpg_base_path = os.path.join(app_base_path, 'jpg_from_dicom')\n",
    "dicom_file_path = os.path.join(dicom_base_path, \"abn*/**/*.dcm\")\n",
    "if 'normal'in DATA_TO_TEST:\n",
    "    dicom_file_path = os.path.join(dicom_base_path, \"normal*/**/*.dcm\")    \n",
    "    \n",
    "jpg_sub_path = 'jpg'\n",
    "#dicom에서 읽은 정보를 jpg로 저장할 경우\n",
    "img_save_path = os.path.join(jpg_base_path, jpg_sub_path)\n",
    "\n",
    "if '_FILE_' in DATA_SOURCE_TYPE and not os.path.exists(img_save_path):\n",
    "    os.makedirs(img_save_path)\n",
    "#-------------------------------------------------------#\n",
    "\n",
    "#----------- test 결과 save path -----------------------#\n",
    "result_save_base_path = os.path.join(app_base_path, 'results')\n",
    "result_save_subpath = os.path.join(DATE + '_' + MODEL_ENV, DATA_TO_TEST)\n",
    "result_save_path = os.path.join(result_save_base_path, result_save_subpath)\n",
    "if not os.path.exists(result_save_path):\n",
    "    os.makedirs(result_save_path)\n",
    "#------------------------------------------------------#    \n",
    "\n",
    "#-------------------- test결과 정보관련 --------------------#\n",
    "number_abnormal_detect_from_normal = 0 #normal 파일에서 abnormal로 검출된 경우의 수\n",
    "####for 테스트 파일목록 Groupping\n",
    "groupby_key_list = [] #그룹명(테스트 파일 단위 그룹 명) 목록\n",
    "groupby_file_list = [] #그룹화된 테스트파일 목록\n",
    "groupby_detected_number_for_files = [] #검출(detect)된 수에 대한 그룹화된 목록(그룹화된 테스트 목록 구조와 동일하게 매핑)\n",
    "#list_not_detected_group_index = [] #검출되지 않은 그룹의 index 목록 \n",
    "#M_max_scores = [] #abnormal 테스트 파일에서 detect된 anchor score 중 가장 높은 score\n",
    "#N_max_scores = [] #normal 각 테스트 파일에서 detect된 anchor score 중 가장 높은 score\n",
    "#----------------------------------------------------------#\n",
    "\n",
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "keras.backend.tensorflow_backend.set_session(get_session())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load RetinaNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = []\n",
    "#resnet50\n",
    "#model_list.append('snapshots/1001_resnet50_ep100_with_valid/resnet50_csv_84.h5')\n",
    "#model_list.append('snapshots/1001_resnet50_ep100_with_valid/1017_snapshot_resnet50_csv_90_ep100_with_valid/resnet50_csv_03.h5')\n",
    "#model_list.append('snapshots/1001_resnet50_ep100_with_valid/1017_snapshot_resnet50_csv_90_ep100_with_valid/resnet50_csv_19.h5')\n",
    "#model_list.append('snapshots/1001_resnet50_ep100_with_valid/1017_snapshot_resnet50_csv_90_ep100_with_valid/resnet50_csv_27.h5')\n",
    "model_list.append('snapshots/1001_resnet50_ep100_with_valid/1017_snapshot_resnet50_csv_90_ep100_with_valid/resnet50_csv_36.h5')\n",
    "\n",
    "#resnet101\n",
    "#model_list.append('snapshots/0928_resnet101_ep100_with_valid/resnet101_csv_61.h5')\n",
    "###model_list.append('snapshots/0928_resnet101_ep100_with_valid/resnet101_csv_59.h5')\n",
    "model_list.append('snapshots/0928_resnet101_ep100_with_valid//1030_snapshot_resnet101_csv_61_ep100_with_valid/resnet101_csv_35.h5')\n",
    "#model_list.append('snapshots/0928_resnet101_ep100_with_valid//1030_snapshot_resnet101_csv_61_ep100_with_valid/resnet101_csv_29.h5')\n",
    "#model_list.append('snapshots/0928_resnet101_ep100_with_valid//1030_snapshot_resnet101_csv_61_ep100_with_valid/resnet101_csv_56.h5')\n",
    "\n",
    "#resnet152\n",
    "#model_list.append('snapshots/0927_resnet152_ep100_with_valid/resnet152_csv_74.h5')\n",
    "#model_list.append('snapshots/0927_resnet152_ep100_with_valid/1012_snapshot_resnet152_csv_74_ep100_with_valid/resnet152_csv_32.h5')\n",
    "model_list.append('snapshots/0927_resnet152_ep100_with_valid/1012_snapshot_resnet152_csv_74_ep100_with_valid/resnet152_csv_45.h5')\n",
    "#model_list.append('snapshots/0927_resnet152_ep100_with_valid/1012_snapshot_resnet152_csv_74_ep100_with_valid/resnet152_csv_53.h5')\n",
    "#model_list.append('snapshots/0927_resnet152_ep100_with_valid/1012_snapshot_resnet152_csv_74_ep100_with_valid/resnet152_csv_57.h5')\n",
    "#model_list.append('snapshots/0927_resnet152_ep100_with_valid/1012_snapshot_resnet152_csv_74_ep100_with_valid/resnet152_csv_84.h5')\n",
    "\n",
    "\n",
    "####################################### 이전모델 ###################################\n",
    "#ensemble 아래 e44 + e29\n",
    "#single e29\n",
    "#model_list.append('snapshots/0326_more_aug/resnet101_csv_44.h5')   \n",
    "#model_list.append('snapshots/0525_add_ncc_mass_data_strong_aug/resnet101_csv_29.h5')\n",
    "#######\n",
    "\n",
    "#model_list.append('snapshots/0620_stronger_aug/resnet101_csv_25.h5')\n",
    "#model_list.append('snapshots/0620_stronger_aug/resnet101_csv_29.h5')\n",
    "#model_list.append('snapshots/0620_stronger_aug/resnet101_csv_47.h5')\n",
    "#model_list.append('snapshots/0620_stronger_aug/resnet101_csv_48.h5')\n",
    "#model_list.append('snapshots/0620_stronger_aug/resnet101_csv_49.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OS_ENV == 'LINUX':\n",
    "    label_csv_path = '/home/huray/data/new_trainset/class_2_malig_or_norm.csv'\n",
    "else:\n",
    "    label_csv_path = 'D:/Work/NCC/data/new_trainset/class_2_malig_or_norm.csv'    \n",
    "    \n",
    "# create a dicom2jpg generator for testing data\n",
    "jpg_generator = DICOM2JPG_Generator(\n",
    "    label_csv_path,\n",
    "    dicom_file_path,\n",
    "    jpg_base_path,\n",
    "    img_save_path,\n",
    "    with_anno = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define and initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dicom 원본  path에서 유일한 파일명을 구성한다.\n",
    "def make_file_name(m_path):\n",
    "    _split = m_path.split('/')\n",
    "    _name = '{}-{}-{}-{}'.format(_split[-4], _split[-3], _split[-2], _split[-1].replace('.dcm', ''))\n",
    "    return _name\n",
    "    \n",
    "############################# !!!!!!!!!!!!!!!!!!!!!!!!!!! ############################# \n",
    "###테스트 결과 출력\n",
    "def get_detection_info():\n",
    "    list_not_detected_group_index = []  # 검출되지 않은 그룹의 index 목록\n",
    "    list_not_detected_group_index_by_annotation = [] # annotation 일치 조건으로 검출되지 않은 그룹의 index 목록\n",
    "    total_not_detected_file = 0 #검출되지 않은 전체 테스트 파일의 수    \n",
    "    i_group_member = 0\n",
    "\n",
    "    print('------------------------------------------------ Result info --------------------------------------------------------')\n",
    "    #print('\\n')    \n",
    "    \n",
    "    for idx_x, row in enumerate(groupby_detected_number_for_files):\n",
    "        i_detections = 0\n",
    "        for idx_y, elem in enumerate(row):\n",
    "            i_detections += elem\n",
    "            if elem == 0:\n",
    "                total_not_detected_file += 1\n",
    "                \n",
    "        if i_detections == 0:\n",
    "            list_not_detected_group_index.append(idx_x)\n",
    "            i_group_member += len(row)\n",
    "            print('({})set have no detection!.'.format(groupby_key_list[idx_x]))\n",
    "\n",
    "    #print('\\n')\n",
    "\n",
    "    #1st print type\n",
    "    #print('Total Number of abnormal case not detected :::::::::: {}'.format(total_not_detected_file))\n",
    "    #print('Number of abnormal case set not detected::::::: {}({} files)'.format(len(list_not_detected_group_index), i_group_member))\n",
    "\n",
    "    #2nd print type\n",
    "    #print('{}/{} files not detected.'.format(total_not_detected_file,len(test_file_list)))\n",
    "    #print('{}({} files)/{} sets not detected.'.format(len(list_not_detected_group_index), i_group_member, len(groupby_key_list)))\n",
    "\n",
    "    #3rd print type\n",
    "    print('{} files'.format(total_not_detected_file))\n",
    "    print('{}({} files) sets  not detected.'.format(len(list_not_detected_group_index), i_group_member))\n",
    "    #print('\\n')\n",
    "    if 'normal' in DATA_TO_TEST:\n",
    "        print('{} abnormal detected.(from {} normal files).'.format(number_abnormal_detect_from_normal,len(test_file_list)))\n",
    "    \n",
    "    print('---------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "###정보 초기화(일부 list 정보에 대한 초기화)\n",
    "def init_info():\n",
    "    global groupby_detected_number_for_files\n",
    "    global number_abnormal_detect_from_normal\n",
    "    for idx_i, row in enumerate(groupby_file_list):\n",
    "        for idx_j, col in enumerate(row):\n",
    "            groupby_detected_number_for_files[idx_i][idx_j] = 0\n",
    "            \n",
    "    #set_anno_file_index()\n",
    "    number_abnormal_detect_from_normal = 0\n",
    "    \n",
    "            \n",
    "###그룹화된 테스트 파일 구조에서 annotation 정보가 있는 파일의 위치를 annotation dict 정보에 set\n",
    "def set_anno_file_index():\n",
    "    global annotation_detect_num_dict\n",
    "    for key in annotation_detect_num_dict:\n",
    "        annotation_detect_num_dict[key] = 0\n",
    "              \n",
    "                \n",
    "#---------------------------------------------------------------------------------------------    \n",
    "#path포함한 파일 목록과, 파일명만(확장자도 제외, 유일성을 위해서 일부 directory명을 포함하여 구성)\n",
    "test_file_list = jpg_generator.dicom_files() #검출 대상 dicom file 목록\n",
    "num_of_test_files = len(test_file_list)    \n",
    "print('total test file : {}'.format(num_of_test_files))\n",
    "\n",
    "#검출대상 파일 목록에 대해 file name, annotation 정보등을 얻는다.\n",
    "for mammo_path in test_file_list:\n",
    "    test_file_name_list.append(make_file_name(mammo_path))\n",
    "'''    \n",
    "    _annos = jpg_generator.read_annotations(mammo_path)\n",
    "    if len(_annos) > 0:\n",
    "        anno_file_list.append(make_file_name(mammo_path))\n",
    "        annotation_num_dict[make_file_name(mammo_path)] = len(_annos)\n",
    "        annotation_detect_num_dict[make_file_name(mammo_path)] = 0\n",
    "'''\n",
    "#print('annotation_pos_dict : {}'.format(annotation_pos_dict))\n",
    "#print('annotation_num_dict : {}'.format(annotation_num_dict))\n",
    "        \n",
    "    \n",
    "########## 테스트 파일목록 정보 set  ######\n",
    "#테스트 파일 목록을 groupby 하기 위해서 정렬\n",
    "test_file_name_list.sort(key=lambda x: '-'.join(x.split('-')[:3]))\n",
    "\n",
    "#테스트 파일 목록을 group by하여 list에 저장\n",
    "#groupby key(그룹핑 기준(단위)는 파일명을 '-'로 split 한뒤 앞쪽 3번째 요소까지 추출함)\n",
    "for key, group in groupby(test_file_name_list, key=lambda x: '-'.join(x.split('-')[:3])):\n",
    "    #그룹 명(key) 목록\n",
    "    print(key)\n",
    "    groupby_key_list.append(key) \n",
    "    temp = list(group)\n",
    "    \n",
    "    #그룹화된 전체 테스트파일 목록 \n",
    "    groupby_file_list.append(temp) \n",
    "    \n",
    "    #그룹화 된 테스트 파일별 검출정보 목록(그룹화된 전체 테스트파일 목록과 동일한 구조로 구성),0 으로 초기화\n",
    "    groupby_detected_number_for_files.append([0]*len(temp))\n",
    "\n",
    "    #그룹화 된 테스트 파일별 검출된 최대 score정보 목록(그룹화된 전체 테스트파일 목록과 동일한 구조로 구성),0 으로 초기화\n",
    "    #M_max_scores.append([0]*len(temp))\n",
    "#print(test_file_name_list)\n",
    "#print(len(groupby_file_list))\n",
    "#print(groupby_file_list)\n",
    "\n",
    "#annotation이 있는 파일 목록을 group by하여 list에 저장\n",
    "#groupby key(그룹핑 기준(단위)는 파일명을 '-'로 split 한뒤 앞쪽 3번째 요소까지 추출함)\n",
    "#파일 목록을 groupby 하기 위해서 정렬\n",
    "'''\n",
    "anno_file_list.sort(key=lambda x: '-'.join(x.split('-')[:3]))\n",
    "for key, group in groupby(anno_file_list, key=lambda x: '-'.join(x.split('-')[:3])):\n",
    "    #그룹 명(key) 목록\n",
    "    temp = list(group)\n",
    "    groupby_annotaion_file_dict[key] = temp\n",
    "'''    \n",
    "#print(groupby_annotaion_file_dict)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#set_anno_file_index()\n",
    "model = []\n",
    "model_count = 0;\n",
    "for model_path in model_list:\n",
    "    model_count += 1\n",
    "\n",
    "    print('{} model {} load..'.format(ordinal(model_count), model_path.split('/')[-1]))\n",
    "            \n",
    "    # Load RetinaNet Models\n",
    "    model.append(keras.models.load_model(model_path, custom_objects=custom_objects))\n",
    "\n",
    "for SCORE_VALUE in SCORE_VALUE_LIST:\n",
    "    print('****************{}*******************'.format(MODEL_ENV))\n",
    "    print('*      Detecting with score {}           *'.format(SCORE_VALUE))\n",
    "    print('*******************************************')\n",
    "    \n",
    "    print('{} test files.'.format(num_of_test_files))\n",
    "        \n",
    "    print(\"start.\")\n",
    "    start = time.time()\n",
    "    for index_count, _fpath in enumerate(test_file_list):\n",
    "        number_of_proper_detection = 0 #검출된 수\n",
    "        b_anno_match = False\n",
    "        b_is_annotation = False\n",
    "        i_anno_detect = 0\n",
    "        detect_list=[]\n",
    "        detect_score_list=[]\n",
    "        \n",
    "        # load image\n",
    "        #image, image_path = val_generator.load_image(index, get_image_path=True)\n",
    "        if '_MEM_' in DATA_SOURCE_TYPE:\n",
    "            image = jpg_generator.load_image(_fpath)\n",
    "        elif '_FILE_' in DATA_SOURCE_TYPE:\n",
    "            image = jpg_generator.load_file_image(_fpath)\n",
    "        else:\n",
    "            print('Define! Data source type...')\n",
    "            break\n",
    "        \n",
    "        # copy to draw on\n",
    "        draw = image.copy()\n",
    "        draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # preprocess image for network\n",
    "        #image = val_generator.preprocess_image(image)\n",
    "        #image, scale = val_generator.resize_image(image)\n",
    "        image = jpg_generator.preprocess_image(image)\n",
    "        image, scale = jpg_generator.resize_image(image)\n",
    "        #annotations = jpg_generator.read_annotations(_fpath)\n",
    "        \n",
    "        # for visualize annotations if imagae include annotation\n",
    "        '''\n",
    "        if len(annotations) > 0: \n",
    "            b_is_annotation = True #현재 파일이 annotation 정보를 가지고 있음\n",
    "            anno_center_list = []\n",
    "            for annotation in annotations:\n",
    "                _center = []\n",
    "                label = int(annotation[4])\n",
    "                b = annotation[:4].astype(int)\n",
    "\n",
    "                _center.append((b[0]+b[2])/2)\n",
    "                _center.append((b[1]+b[3])/2)\n",
    "                anno_center_list.append(_center)\n",
    "                \n",
    "                cv2.rectangle(draw, (b[0], b[1]), (b[2], b[3]), (50, 50, 255), 2)\n",
    "                caption = \"{}\".format(jpg_generator.label_to_name(label))\n",
    "                cv2.putText(draw, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 3, (0, 0, 0), 5)\n",
    "                cv2.putText(draw, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 3, (255, 255, 255), 4)\n",
    "        '''\n",
    "        for cur_model in model:\n",
    "            # process detection\n",
    "            _, _, detections = cur_model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "\n",
    "            # compute predicted labels and scores\n",
    "            predicted_labels = np.argmax(detections[0, :, 4:], axis=1)\n",
    "            scores = detections[0, np.arange(detections.shape[1]), 4 + predicted_labels]\n",
    "\n",
    "            # correct for image scale\n",
    "            detections[0, :, :4] /= scale\n",
    "\n",
    "            for idx, (label, score) in enumerate(zip(predicted_labels, scores)):\n",
    "                if score < SCORE_VALUE or label != 0:\n",
    "                    continue\n",
    "\n",
    "                number_of_proper_detection += 1\n",
    "                detect_list.append(detections[0, idx, :4].astype(int))\n",
    "                detect_score_list.append(score)\n",
    "\n",
    "        #이미지에서 (조건에 부합되게)detect된 것이 있을 경우\n",
    "        if number_of_proper_detection > 0:\n",
    "            #ensemble 모델들을 통해 얻은 선택 영역들에 대해 중복영역 등을 고려하여 최종 선택\n",
    "            \n",
    "            #1.검출영역 선택시 병합없이 선택\n",
    "            #selected_detection_list_idxs = my.select_deteced_list(detect_list, detect_score_list)\n",
    "            \n",
    "            #2.검출영역 선택시 일정 조건에 따라 영역을 병합하며, Score는 병합된 영역의 평균으로 대체된다.\n",
    "            selected_detection_list_idxs = my.select_deteced_list_wih_merge(detect_list, detect_score_list)\n",
    "        \n",
    "            for idxx, b in enumerate(detect_list):\n",
    "                if selected_detection_list_idxs[idxx] == 0: #검출영역 정리되어 선택된 것만....\n",
    "                    '''\n",
    "                    if b_is_annotation and len(anno_center_list) > 0:\n",
    "                        for anno_center in anno_center_list:\n",
    "                            if b[0]<anno_center[0]<b[2] and b[1]<anno_center[1]<b[3]:\n",
    "                                b_anno_match = True # annotation과 매칭되는 검출정보가 있음\n",
    "                                i_anno_detect += 1\n",
    "                                break\n",
    "                    '''\n",
    "                    #cv2.rectangle(draw, (b[0], b[1]), (b[2], b[3]), (0, 255, 0), 5)\n",
    "                    cv2.rectangle(draw, (b[0], b[1]), (b[2], b[3]), (0, 255, 0), 2)\n",
    "                    #caption = \"{} {:.3f}\".format(val_generator.label_to_name(label), detect_score_list[idxx])\n",
    "                    caption = \"{} {:.3f}\".format(jpg_generator.label_to_name(label), detect_score_list[idxx])\n",
    "                    cv2.putText(draw, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 3, (0, 0, 0), 5)\n",
    "                    cv2.putText(draw, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 3, (255, 255, 255), 4)\n",
    "\n",
    "            #normal file에서 detect된 경우\n",
    "            if 'normal' in _fpath:\n",
    "                number_abnormal_detect_from_normal += 1            \n",
    "\n",
    "            ##################### 그룹화된 테스트 파일 정보와 동일한 구조의 detection 정보 목록에 반영 ##############\n",
    "            # 테스트 파일 그룹 목록에서 현재 파일의 위치를 구함    \n",
    "            img_indics = my.find(groupby_file_list, make_file_name(_fpath))\n",
    "            if len(img_indics) > 0:\n",
    "                #groupby_detected_number_for_files[img_indics[0]][img_indics[1]] += number_of_proper_detection\n",
    "                groupby_detected_number_for_files[img_indics[0]][img_indics[1]] = 1\n",
    "                \n",
    "             # annotation 검출결과(개수 등) 저장\n",
    "            '''\n",
    "            if b_is_annotation:\n",
    "                annotation_detect_num_dict[make_file_name(_fpath)] = i_anno_detect\n",
    "            '''\n",
    "        ############검출된 정보를 이미지에 표시, 저장################\n",
    "        #1. 모든 파일저장, annotation 유무에 관계없이, 검출영역 정보 표시\n",
    "        #cv2.imwrite(os.path.join(result_save_path, '-'.join(image_path.split('/')[-2:])), draw)\n",
    "        cv2.imwrite(os.path.join(result_save_path, make_file_name(_fpath)+'.jpg'), draw)\n",
    "        \n",
    "        #2. annotation 정보를 가지고 있는 파일만 저장, 검출 결과도 함께 표시\n",
    "        '''\n",
    "        if b_is_annotation:\n",
    "            #cv2.imwrite(os.path.join(result_save_path, '-'.join(image_path.split('/')[-2:])), draw)\n",
    "            cv2.imwrite(os.path.join(result_save_path, make_file_name(_fpath)+'.jpg'), draw)\n",
    "\n",
    "            #annotation 미 검출(annotation 검출 조건이 1개도 만족되지 않음)된 파일만 따로 저장\n",
    "            if not b_anno_match:\n",
    "                # save the image into file\n",
    "                cv2.imwrite(os.path.join(result_anno_miss_save_path, make_file_name(_fpath)+'.jpg'), draw)\n",
    "        '''\n",
    "        del detect_list\n",
    "        del detect_score_list\n",
    "\n",
    "        #print('{}/{} completed.\\r'.format(index+1,num_of_test_files), end='')\n",
    "        print('{}/{} completed.\\r'.format(index_count+1,num_of_test_files), end='')\n",
    "\n",
    "    print(\"end({:.2f} minutes elapsed).\".format((time.time() - start)/60))\n",
    "\n",
    "    # release the memory\n",
    "    #del model\n",
    "    #keras.backend.clear_session()\n",
    "        \n",
    "    get_detection_info() #detection 결과 출력\n",
    "   \n",
    "    print('\\n')\n",
    "    \n",
    "    #다음 Score로 테스트하기 위해 이전 검출 정보를 초기화 해줘야 함...\n",
    "    init_info()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
